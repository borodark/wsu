---
title: "Lab Exercise Week 5 and Homework 2"
author: "Your Name Here"
date: "October 1, 2019"
output: html_document
---

## Requirements
1. Do the following exercises, answer Q1 to Q13, and present your answers in a HTML file generated by RMarkdown. Specifically, the RMarkdown file of this document is provided as a template and starting point, so just finish this document by typing up your answers after each question, and format your answers appropriately. Note that the answers for the first 3 questions are given as an example. 

2. Do exericses ISLR 3.7 Problem 1, 3 and 4. Type up your answers at the end of this document. No need to transcribe the problem descriptions, just clearly label your answers to match with the problem number. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment="")
```

## Build a Multiple Linear Regression Model and Assess its Performance

First, load the *MASS* package that contains the Boston dataset. The Boston data set is loaded with package, use `?Boston` to learn about the meanings of each column.
```{r}
library(MASS) 
```

* __Q1__: In the Boston data set, what is the Total Sum of Squares (TSS) of the median house value _medv_? 
```{r}
 (TSS <- sum((Boston$medv - mean(Boston$medv))^2))

```

Fit _medv_ (median house value) as a linear function of _lstat_ (percentage of lower status of the population) and _age_ (proportion of units built prior to 1940). 
```{r}
lm.fit <- lm(medv ~ lstat + age, data = Boston)
```

From the model summary, answer these questions:

* __Q2__: What is the Residual Sum of Squares (RSS) of this fit? 
```{r} 
(RSS <- (nrow(Boston)-2-1)*(summary(lm.fit)$sigma)^2)
```

* __Q3__: How much proportion of the variance in _medv_ is accounted for by this fit? 
```{r} 
summary(lm.fit)$r.sq
```

* __Q4__: Overall, is there a relationship between the response variable _medv_ and the predictors _lstat_ and _age_? How do you make such a conclusion? 
```{r}
summary(lm.fit)
```
There is a relationship. The `lstat` has more predictive power then `age` becauase of low enougth _p-value_  `< 2.2e-16` for `lstat` variable: ~55%  of variance in _medv_ that is explained by the model.

* __Q5__: Is there a relationship between _medv_ and each of the predictors? How do you tell?
```{r}

pairs(~ lstat + medv, Boston)
pairs(~ age + medv, Boston)

```

There is a _nonlinear_ function exists that fits relationships between `lstat` and `medv` but `age` has less obvious dependency `medv`. 

* __Q6__: What is the estimated standard deviation of the irreducible error in the model $\text{medv} = \beta_0 + \beta_1 \cdot \text{lstat} + \beta_2 \cdot \text{age} + \epsilon$. 

```{r}
#Residual standard error: 6.173 on 503 degrees of freedom
summary(lm.fit)$sigma
```
* __Q7__: How do you interpret the coefficient estimate on _age_, i.e., the value 
```{r} 
format(coef(lm.fit)['age'], digits=3)
```
, in the model context?
It means that 
$\ \beta_2 = 0.0345$

in the full model equasion will be:

$\text{medv} = 33.22276 + -1.03207 \cdot \text{lstat} + 0.0345 \cdot \text{age} + \epsilon$

## Build a Full Model and Compute VIFs

Let's first check if all columns of the data set are numeric hence can be used as predictors.

```{r}
sapply(Boston, mode)
```

Are all columns of the numeric type? 
```{r}
all(sapply(Boston, mode) == "numeric")
```
. Let's try using all columns (except for _medv_, of course) as predictors and fit a full model. 

```{r}
lm.fit.full <- lm(medv ~ ., data = Boston)
```

Now display the model summary using 
```{r} 
summary(lm.fit.full)
``` 
and answewr these questions.

* __Q8__: How many predictors are used in this model fit?
_13_ predictors.

* __Q9__: Which predictors have a significant effect on the response variable at a confidence level of 0.95?

_All_ except:

- `indus        2.056e-02  6.150e-02   0.334 0.738288`
- `age          6.922e-04  1.321e-02   0.052 0.958229`


* __Q10__: Does _age_ present a significant effect on _medv_ in this model?  

Clearly _not_!


Let's calculate the Variance Inflation Factor (VIF) of each predictor in the above full model. VIF of a predictor $X_j$ measures how well $X_j$ can be represented as a linear combination of other predictors used in the model. A high VIF indicates that the predictor has a high multicollinearity with other predictors, thus should probably be excluded from the set of predictors to improve the model fit. 
VIF of a predictor $X_j$ is calculated by the formula $\text{VIF}_j = \frac{1}{1-R_j^2}$, where $R_j^2$ is the R-Square value of the model fit by using $X_j$ as the response variable and all other predictors used in the original model as predictors. For instance, to calculate the VIF of _age_ in the context of `lm.fit.full` model:

```{r}
(VIF_age <- 1/(1-summary(lm(age ~ .-medv, data = Boston))$r.sq))
```

Note that in the above line, `lm(age ~ .-medv, data=Boston)` means to fit a linear model for _age_ using all columns of `Boston` but `medv`. 

We can use the `vif` function in the `car` package to calculate the VIF for all predictors in a model, as follows.

```{r}
#install.packages("car")  # run this line if you have not installed the "car" package before
library(car)
vif(lm.fit.full)
```


## Model Selection

Now, let's exclude _age_ from the full model and fit again. 

```{r}
lm.fit.all_but_age <- lm(medv ~ . - age, data = Boston)
```

Display the 

```{r}
summary(lm.fit.all_but_age)
```

and answer these questions.

* __Q11__: Compare the Multiple R-squared and Adjusted R-sqaured values between this model and the full model. Comment on the differences. Which model do you think is better?

`Multiple R-squared:  0.7406,	Adjusted R-squared:  0.7343` - All but `age`
`Multiple R-squared:  0.7406,	Adjusted R-squared:  0.7338` - Including `age`

_Higher Adjusted R-squared_ of the _All but_ `age` model suggests its supperiority.



* __Q12__: Compute the AIC and BIC of the model `lm.fit.full` and `lm.fit.all_but_age`, respectively. Use the function `AIC(lm.fit.full)` and `BIC(lm.fit.full)`. Compare the two models in terms of AIC and BIC. Does the conclusion consistent with what you get in Q11?
```{r}
AIC(lm.fit.full)
BIC(lm.fit.full)

```
```{r}
AIC(lm.fit.all_but_age)
BIC(lm.fit.all_but_age)

```

_Lower_ `AIC` and `BIC` of `lm.fit.all_but_age` supports the current idea of this model bein better.

* __Q13__: Pick a termination criteria (i.e., Adj. R-squared, AIC or BIC) and carry out the Backward Selection procedure to find the best fit. 



## ISLR Exercises (Section 3.7)

### Problem 1:


### Problem 3:


### Problem 4:

